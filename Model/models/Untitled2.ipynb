{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e6e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "import numpy as np\n",
    "import gensim\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67db781",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78278e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cut(comments):\n",
    "     words = jieba.cut(comments)\n",
    "     return ','.join(words)# ä»¥é€—å·è¿æ¥åˆ†å‰²åçš„è¯\n",
    "#applyå‡½æ•°é»˜è®¤ä¼šæŒ‰è¡Œåº”ç”¨word_cutå‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a0ee87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»txtæ–‡ä»¶ä¸­è¯»å–åœæ­¢è¯\n",
    "def Get_stopwords(path):\n",
    "    stopwords=[]\n",
    "    with open(path,encoding='utf-8') as words:\n",
    "        stopwords.extend([i.strip() for i in words.readlines()])\n",
    "    return stopwords\n",
    "stopwords=Get_stopwords(\"./stopwords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b72e6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(segmented_text):\n",
    "     #å­—ç¬¦ä¸²è½¬ä¸ºåˆ—è¡¨\n",
    "     segmented_list = segmented_text.split(',')#æ ¹æ®é€—å·åˆ†éš”ç¬¦ï¼Œå°†å­—ç¬¦ä¸²è½¬ä¸ºåˆ—è¡¨\n",
    "     #å»åœç”¨è¯\n",
    "     words_without_stopwords = []\n",
    "     for w in segmented_list:\n",
    "         if w not in stopwords:\n",
    "             words_without_stopwords.append(w)\n",
    "     return words_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff223c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_blanks(comments):\n",
    "    for com in range(len(comments)):\n",
    "        while ' ' in comments[com]:\n",
    "            comments[com].remove(' ')\n",
    "        while '' in comments[com]:\n",
    "            comments[com].remove('')\n",
    "        while '\\n' in comments[com]:\n",
    "            comments[com].remove('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bcce281",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./different_tokenizer/tokenizer_50000_100.pickle', 'rb') as handle: \n",
    "    tokenizer = pickle.load(handle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38cd4743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "model=models.load_model(\"./72.58%_200_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "264dec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment=\"ç¬‘æ­»ï¼Œå¥‡å¼‚åšå£«ç«™åœ¨è‡ªç”±å¥³ç¥åƒä¸Šå¯¹å…¨ä¸–ç•Œçš„äººè¿›è¡Œæ´—è„‘ğŸ˜“\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d3fc8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ç¬‘', 'æ­»', 'å¥‡å¼‚', 'åšå£«', 'ç«™', 'è‡ªç”±', 'å¥³ç¥åƒ', 'å…¨ä¸–ç•Œ', 'æ´—è„‘', 'ğŸ˜“']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27889e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment=word_cut(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0272a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment=remove_stopwords(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fb9fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment=[comment]#å…³é”®ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48632bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Remove_blanks(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dd36fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=tokenizer.texts_to_sequences(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ece7b73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[86, 39, 6198, 3748, 530, 174, 17348, 1403, 1919, 11999]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aec4d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pad_sequences(sequences,maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ab3b165",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "   Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/bidirectional/forward_lstm/PartitionedCall]] [Op:__inference_predict_function_3448]\n\nFunction call stack:\npredict_function -> predict_function -> predict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9312/3037987753.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:    Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/bidirectional/forward_lstm/PartitionedCall]] [Op:__inference_predict_function_3448]\n\nFunction call stack:\npredict_function -> predict_function -> predict_function\n"
     ]
    }
   ],
   "source": [
    "model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7e65f3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(comment,tokenizer,model):\n",
    "    comment=word_cut(comment)\n",
    "    comment=remove_stopwords(comment)\n",
    "    comment=[comment]#å…³é”®ï¼\n",
    "    Remove_blanks(comment)\n",
    "    sequences=tokenizer.texts_to_sequences(comment)\n",
    "    data=pad_sequences(sequences,maxlen=maxlen)\n",
    "    print(model.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebfb11f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\CHEN\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.624 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.760143]]\n"
     ]
    }
   ],
   "source": [
    "predict(comment,tokenizer,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2fdac0",
   "metadata": {},
   "source": [
    "å–è‡ªâ€”â€”èœ˜è››ä¾ ï¼šè‹±é›„æ— å½’çš„éƒ¨åˆ†å½±è¯„ï¼š\n",
    "\n",
    "å¯¹äºæ²¡æœ‰è¡¨è¾¾æƒ…æ„Ÿçš„å½±è¯„çš„è¾¨æåº¦ä¸é«˜â€”â€”å°å­©å­çš„æ€ç»´é—¯ç¥¸äº†ï¼›å»ºè®®ç¾å›½å®è¡Œé«˜è€ƒåˆ¶åº¦ï¼Œå”¯åˆ†æ•°è®ºï¼Œå…¬å¹³å¯¹å¾…æ¯ä¸€ä½é«˜ä¸‰è€ƒç”Ÿï¼ˆä¸é«˜ï¼‰ï¼›ç¬‘æ­»ï¼Œå¥‡å¼‚åšå£«ç«™åœ¨è‡ªç”±å¥³ç¥åƒä¸Šå¯¹å…¨ä¸–ç•Œçš„äººè¿›è¡Œæ´—è„‘ğŸ˜“ã€‚\n",
    "\n",
    "å¤ªé•¿ï¼Œé«˜åˆ†ä½†æœ‰ä¸€å¤§éƒ¨åˆ†æ˜¯åœ¨è®²ä¸å¥½çš„åœ°æ–¹æ—¶ä¼šå‡ºç°åˆ†ç±»ä¸ºå·®è¯„çš„æƒ…å†µâ€”â€”èœ˜è››ä¾ çœ‹è¿‡å¤ªå¤šéäº†ï¼Œè¿˜æ˜¯å–œæ¬¢ï¼Œåªæ˜¯è¿™ä¸ªç”µå½±æœ€å¼€å§‹çš„è®¾å®šå°±ä¸å¯¹ï¼Œä¸ºäº†è§£å†³ä¸€ä¸ªå±æœºï¼Œè®©å…¨ä¸–ç•Œå¿˜è®°ä»–çš„èº«ä»½ï¼Œè€Œå¥‡å¼‚åšå£«ä¹Ÿè½»æ˜“çš„åŒæ„äº†ï¼Œæœ‰ç‚¹æ‰¯ï¼Œåæ´¾ä»¬çªç„¶é›†ä½“åæ°´ï¼Œä¹Ÿå¾ˆæ‰¯ï¼Œè®¾å®šä¸è¡Œï¼Œæ•…äº‹ä¸å¥½ï¼Œä¸è¿‡ä¸‰ä¸ªèœ˜è››ä¾ ç›¸é‡ï¼Œè¿˜æ˜¯è®©äººæ„Ÿæ…¨è‰¯å¤šã€‚â€”â€”å‰§æƒ…ä¸€èˆ¬èˆ¬ï¼Œæ¼«ç”»è‹±é›„ç”µå½±å‰§æœ¬å·²ç»åˆ°äº†ç“¶é¢ˆï¼ŒåŸºæœ¬å°±æ˜¯åœ¨ä¸åæ´¾äº§ç”Ÿçº è‘›çš„è¿‡ç¨‹ä¸­æ˜ å°„å®¿å‘½ï¼Œçˆ±æƒ…ï¼Œäº²æƒ…è¿™äº›ï¼Œä½†æ­¤éƒ¨ä¸‰å‚»ç›¸é‡è¿˜æ˜¯æŒºå¥½çœ‹çš„ã€‚æ¼«å¨åœ¨è¿™ç»™å¤§IPç»­å‘½ï¼Œè¿˜ä¸å¦‚å¤šèŠ±å¿ƒæ€å¼€è¾Ÿæ–°çš„è‹±é›„çº¿ï¼ŒDCçš„å’Œå¹³ä½¿è€…å°±å¾ˆæˆåŠŸï¼Œæ²¡æœ‰å¤¸å¼ çš„è¶…èƒ½åŠ›ï¼Œæœ‰è¡€æœ‰è‚‰æœ‰ç¬‘ç‚¹ã€‚ï¼ˆå¥½å‡ºå·®ï¼‰ï¼›\n",
    "\n",
    "ä¸æ˜¯ç™½è¯â€”â€”é«˜å¤„ä¸èƒœå¯’ï¼Œè‡ªå¤è‹±é›„å¤šå­¤èº«ã€‚å°‘å¹´æœ¬è‚†æ„ï¼Œåœ¨ä¸€æ¬¡æ¬¡å¤±å»ä¸­å­¦ä¼šå…‹åˆ¶ï¼Œå‹æŠ‘æ„¤æ€’ï¼Œèˆå¼ƒå¿µæƒ³ï¼Œéšå¿çˆ±æ„ã€‚æ‚²æ¬¢ç¦»åˆæ˜¯å±äºå‡¡äººçš„ï¼Œç¨šå«©çš„èœ˜è››ä¾ ç»ˆå°†èœ•å˜ã€‚åªæ˜¯äººç‰©å¤ªå¤šï¼Œè¢«èˆå¼ƒçš„è§’è‰²çœŸçš„å¤ªçº¸ç‰‡å•¦ï¼éƒ¨åˆ†åœºæ™¯åˆ‡æ¢ä¹Ÿå¾ˆå¾®å¦™ã€‚magicæ€ä¹ˆå°±é‚£ä¹ˆéšä¾¿äº†å‘¢ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
